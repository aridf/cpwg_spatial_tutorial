---
title: "Spatial regression demos"
author: "Chris Hess"
date: "5/4/2021"
output:
  github_document:
    df_print: paged
    toc: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r}
#dependencies
library(tidyverse)
library(sf)
library(spatialreg)
library(spdep)
library(INLA)
library(mgcv)

#load the Boston housing Ddata
boston <- read_sf(system.file("shapes/boston_tracts.shp", package = "spData")) %>%
  st_transform(crs = 5070) #epsg for USA Contiguous Albers Equal Area Conic, USGS
```

<br>

## Overview

This vignette is focused on demonstrating code for setting up and estimating spatial regression models in R. The models are focused on the effect of air quality on home values, with the precise specifications drawn from Harris & Rubenfield 1978's original use of the Boston data and a more recent paper (Bivand 2017) that revisits the topic with models estimated in R. 

Check out these papers if interested the nuts and bolts of how the covariate specifications but this should not be material to understanding the setup for these models in R.

<br>

## Boston housing data

For detailed information, check out the `boston` data's R documentation page. This is a set of built-in data that come with the `spData` library that can be loaded like we have above or that can be downloaded from many sources as standalone files (GeoDa's data center, Kaggle, etc.)

```{r, results = "asis"}
?boston
```

Here's a quick look at the data for right now though:

```{r}
glimpse(boston)
```


<br>

### Spatial extent

We map the `boston` data's corrected median home value (`CMEDV`) here for reference.

```{r}
#CMEDV - corrected median values of owner-occupied housing in USD 1000
ggplot(boston, aes(fill = CMEDV)) +
  geom_sf(color = NA) +
  labs(fill = "Median owner-occupied housing value") +
  scale_fill_viridis_b() +
  theme(legend.position = "bottom")
```

<br>

## Getting things ready

<br>

#### Polygon -> Neighborhood list

Contiguity based neighbors are probably the most common type of neighbor lists used for spatial regressions. Here we show how to use function `poly2nb()` to use a spatial object to a create neighborhood list.

`knearneigh` and `knn2nb()` provide an alternative nearest neighbor approach for generating neighborhood lists for reference.

```{r}
#first add a row number that will index neighborhood list entries to relate to df rows
boston <- boston %>% mutate(tract_idx = row_number())

#contiguity neighborhood list can be created with poly2nb (nb: fn wants sp* object not sf)
boston_nb <- poly2nb(as_Spatial(boston), row.names = boston$tract_idx)

#this is a little more useful than the print method for nb objects
summary(boston_nb)
```

<br>

#### Removing empty neighbor sets

NB: regarding zero policy: you technically can set `zero.policy = TRUE` to ignore empty neighbor sets but these models aren't really intended to have isolates / islands. See responses from Roger Bivand (package author) dug up from the R spatial listserv on this matter:

> The lagged value of a no-neighbour observation is not well defined, as setting 0 may be misleading, and setting NA will break the next operations, in this case calculating measures based on the weights.
> If you really want regions with no neighbours, you must use zero.policy = TRUE everwhere - because usually you are advised not to generate such neighbour objects (the theoretical properties of tests etc. were developed for graphs with all regions connected.

You can use subset with the cardinality of the neighborhood list to remove these empty neighbor cases. First remove the corresponding rows from the data frame that will be used for modeling, then remove the neighborhood list entries.

There aren't any islands in these data but the following code is what would be used in the event that there were.

```{r}
boston <- subset(boston, subset = card(boston_nb) > 0)
boston_nb <- subset(boston_nb, subset = card(boston_nb) > 0)
```

<br>

#### Visualizing the neighborhood structure

Sometimes it can be useful to show the neighborhood structure across spatial units as a way of identifying whether this spatial pre-processing is producing the desired outcome.

```{r}
#we need to translate the nb object into a network of vectors for plotting
boston_neighbors_sf <- st_as_sf(nb2lines(boston_nb, coords = coordinates(as_Spatial(boston)),
                                         proj4string = proj4string(as_Spatial(boston))))

#once we have that, we can assemble a map showing the neighborhood structure
ggplot(boston) + 
  geom_sf(fill = 'grey70', color = 'white') +
  geom_sf(data = boston_neighbors_sf, lwd = .1) +
  geom_sf(data = st_centroid(st_geometry(boston)), size = .75) +
  theme_void()
```

<br>

#### Neighborhood list -> spatial weights matrix

The neighborhood list gets us part of the way to where we need to go. The primary spatial regression functions provided by the `spatialreg` library all expect a `listw` spatial weights object that is one step removed from the neighborhood list we've already created. 

`nb2listw()` handles this task of creating a spatial weights object, with row-standardized `style = "W"` (default) or `style = "B"` for binary coding being the most common approaches for constructing spatial weights.

```{r}
#row standardized
boston_listw_w <- nb2listw(boston_nb, style = "W")

#unstandardized
boston_listw_b <- nb2listw(boston_nb, style = "B")
```

<br>

`listw` can be coerced into a sparse matrix that is potentially useful when the data in question are large and estimation of models is producing issues NaNs due to a "poorly conditioned" numerical Hessian. 

We can visualize the matrix with `image()` to see what it describes, though this admittedly isn't super useful. The regression functions eventually take the `sp_powers_traces` created here as as an additional parameter.

```{r}
#coerce to sparse matrix
boston_csparse_matrix <- as(boston_listw_w, "CsparseMatrix")

#visualize the sparse matrix
image(boston_csparse_matrix)

#this is what is used within spatial regression functions in large data cases
boston_listw_powers_traces <- trW(boston_csparse_matrix, type = "mult")
```

<br>

## Estimating spatial models

### Linear regression baseline

```{r}
#estimate the Harrison and Rubenfield model for housing price ~ air quality 
linear_model <- lm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT), 
                   data = boston)

#look at model coefficients
summary(linear_model)

#add column of fitted values to boston sf object
boston$lm_pred <- predict(linear_model)
```

<br>

### Residual spatial autocorrelation

#### Map the residual spatial autocorrelation

```{r}
#choropleth map to investigate spatial structure in residuals
ggplot(boston, aes(fill = log(CMEDV) - lm_pred)) +
  geom_sf(color = NA) +
  scale_fill_gradient2()
```

```{r}
#aspatial plots for residual analysis
#plot(linear_model)
```
<br>

#### Moran's I test for residual spatial autocorrelation

```{r}
#test for residual spatial autocorrelation with Moran's I
lm.morantest(linear_model, boston_listw_w)
```

<br>

#### Lagrage multiplier diagnostics for spatial dependence

```{r}
lm.LMtests(linear_model, boston_listw_w, test = "all")
```

<br>

### Spatial models

Simultaneous autoregressive models are typically estimated with maximum likelihood and most commonly found in papers from economics, sociology and other social sciences where inference on a particular association is the primary objective.

There are also full Bayesian methods for SAR models in various frameworks like stan and INLA.

<br>

#### Three spatial extensions from OLS

1. Endogenous interaction
2. Exogenous interaction effects
3. Spatially structured error terms

Any combination of these can be incorporated under what is called the General Nesting Spatial Model, but it is useful to go through each individually first.

<br>

#### Spatial lag model (SLM)

Spatial lag models are used to capture when a dependent variable y in place i is affected by the independent variables in both place i and j. 

This spatial dependence between units violates the OLS assumption of independent error terms as well as the assumption of independence of observations, so resulting estimates are potentially biased and inefficient. 

These models estimate a term $\rho$ that denotes the spatial dependence, whether this is positive (reflects diffusion across like places) or negative (reflects resistance process like places)

```{r, message = FALSE, warning = FALSE}
#estimate spatial lag model
spatial_lag_model <- lagsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                              data = boston,
                              listw = boston_listw_w)

#summary of spatial lag model
summary(spatial_lag_model)

#fitted values from spatial lag model
boston$slm_pred <- predict(spatial_lag_model)

#to pass the vector of powered spatial weights matrix traces output by trW
#according to the docs "when given, insert the asymptotic analytical values 
#into the numerical Hessian instead of the approximated values; may be used to 
#get around some problems raised when the numerical Hessian is poorly conditioned, 
#generating NaNs in subsequent operations;
# lagsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#            AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#          data = boston,
#          listw = boston_listw_w,
#          method = "Matrix",
#          trs = boston_listw_powers_traces)
```

<br>

#### Spatial error model (SEM)

Spatial error refers to when the error terms across different spatial units are correlated and can reflect omitted, spatially-correlated covariates that would bias inference on a focal term. Spatial error in linear regression only violates the assumption of uncorrelated error terms, making estimates inefficient. 

The spatial error model (SEM) is thus more of a nuisance correction than a substantively different model from linear regression like spatial lag models. That is, the error term is decomposed into a spatially structured component based on neighbors, and a non-structured component that captures the rest. 

For this to alleviate the residual spatial autocorrelation, the user must (importantly) provide the correct neighborhood structure through the weights matrix. One could certainly keep testing the residuals for spatial structure after trying different neighborhood structures, but this is not very appealing from a methodological standpoint.

```{r, message = FALSE, warning = FALSE}
#estimate spatial error model
spatial_error_model <- errorsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                                  data = boston,
                                  listw = boston_listw_w)

#summary of spatial error model
summary(spatial_error_model)

#fitted values from spatial error model
boston$sem_pred <- predict(spatial_error_model)
```

<br>

#### Spatial Durbin model (SDM)

Direct effects via regular terms, indirect effects via spatially lagged terms. 

```{r, message = FALSE, warning = FALSE}
spatial_durbin_model <- lagsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                                 data = boston,
                                 listw = boston_listw_w,
                                 Durbin = TRUE) 
#sumamry of spatial durbin model
summary(spatial_durbin_model)

#fitted values for spatial durbin model
boston$sdm_pred <- predict(spatial_durbin_model)

#estimate spatial error durbin
# errorsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#             AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#            data = boston,
#            listw = boston_listw_w,
#            Durbin = TRUE) 

#you can also do a "spatial lag of x" model with only a set of spatially lagged covariates
# errorsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#             AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#            data = boston,
#            listw = boston_listw_w,
#            Durbin = ~ CRIM) 
```

<br>

#### General nested spatial model (GNSM)

This model includes a spatially lagged dependent variable, spatially lagged independent variables and spatially structured error terms. It is essentially a combined version of all three spatial extensions to OLS. 

Without the spatially lagged independent variables (i.e. the Durbin component) it is known as a simulataneous autoregressive combined (SAC) / simulataneous autoregressive-autoregressive (SARAR) model.

```{r, message = FALSE, warning = FALSE}
#estimate general nested spatial model
spatial_nested_model <- sacsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                                 data = boston,
                                 listw = boston_listw_w,
                                 Durbin = TRUE) 

#summary for general nested spatial model 
summary(spatial_nested_model)

#estimate spatial autoregressive combined (SAC/SARAR) model
# spatial_combined_model <- sacsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#                                     AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#                                    data = boston,
#                                    listw = boston_listw_w,
#                                    durbin = TRUE) 
```

<br>

#### Impacts

A quantity known as the model impacts are needed to properly understand model associations when there are spatially lagged predictors or outcomes. These parse out the effect into direct and indirect effects of a covariate on the outcome. See below for how the `spatialreg` documentation describes this:

> The calculation of impacts for spatial lag and spatial Durbin models is needed in order to interpret the regression coefficients correctly, because of the spillovers between the terms in these data generation processes (unlike the spatial error model). 

The `impacts()` function will greatly simplify the estimation of overall impacts for a given term, but does produce an odd data.frame-like structure that isn't readily coercable / usable as an actual data frame.

Accordingly, we use `imap()` and `reduce()` to iterate through our models, computing the impacts and then wrangling results into what is ultimately a list of data frames rather than a list of `lagImpact` objects by default.

```{r, message=FALSE, warning=FALSE}
#compute impacts
impacts <- imap(list(spatial_lag_model, spatial_durbin_model, spatial_nested_model),
               
                #for each list element, compute impacts
                ~ impacts(.x, listw = boston_listw_w) %>%
                  
                  #reduce to a data frame per model
                  reduce(bind_cols) %>%
                  
                  #fix the column names that are lost
                  rename(direct = ...1, indirect = ...2, total = ...3) %>%
                  
                  #label the model the impacts correspond to based on list elt
                  mutate(model = .y))

#reduce list to data frame
impacts <- reduce(impacts, bind_rows)
```

```{r}
#make the model measure informative
impacts <- impacts %>% 
  mutate(model = case_when(
    model == 1 ~ "1. Spatial Lag Model",
    model == 2 ~ "2. Spatial Durbin Model",
    model == 3 ~ "3. Nested Spatial Model"
  ))

#we need to readd the covariate names, sans intercept and Rho
impacts$term <- rep(names(coefficients(spatial_lag_model)[-c(1:2)]), 3)

#pivot longer for ggplot
impacts <- impacts %>%
  pivot_longer(-c(model, term, total)) 


ggplot(impacts, aes(y = term, x = value, fill = name)) +
  facet_grid(~ model) +
  geom_bar(stat = "identity", position = "stack")
```

<br>

### Some takeaways about spatial econometric models

1. Spatial models do allow one to explictly model phenomena like spillover effects across a set of areas.

2. They also potentially provide a solution for spatially structured model errors, but this rests on assumption that the chosen neighborhood matrix is the right one, and not some other definition of neighboring (e.g., first and second order neighbors).

3. They add considerable complexity in terms of both model estimation and interpretation.

<br>

### A special issue of interest:

In 2012, _Regional Science_ published a set of articles all centered around taking stock of spatial econometric models' development and research applications. The introduction to this issue, along with the three substantive articles are all in this repo and are highly informative if these models are on your radar.

- [Partridge et al 2012, _Special issue introduction_](./literature/partridge-et-al-2012-regional-science.pdf) 
  - This is useful for context about limitations to these models, both in terms of sensitivity to specification and causal identification.
  - > We commissioned three peer-reviewed papers to assess how spatial
econometrics should be used. In sum, their prescriptions range from sweeping changes to a proposal for more nuanced changes of standard practice. 
  - > The most sweeping is articulated in the paper by Gibbons and Overman (2012). They contend that identification is almost always impossible with standard spatial econometric practice
  - > The second paper is McMillen (2012). Like Gibbons and Overman (2012), McMillen’s starting point is that standard spatial econometrics rests on very restrictive assumptions and that identification is very difficult. Specifically regarding spatial lag and spatial error models, McMillen states “Though they play a useful role in detecting various forms of model misspecification, they are apt to be viewed as the correct parametric form for a model when, in fact, they are simply a convenient way to control for unknown sources of spatial clustering among model residuals or the dependent variable.”
  - > The final paper is by Corrado and Fingleton (2012). They agree with the two other papers that standard spatial econometrics has too often been misapplied. Namely, there is not enough emphasis on both theory or in simply forming a conceptual framework to understand spatial spillovers. Thus, empirical models are misspecified, making accurate inference challenging.

- [Gibbons and Overman 2012, _"Mostly pointless spatial econometrics"_](./literature/gibbons-and-overman-2012-regional-science.pdf) 
  - > Many spatial econometricians are surely aware of these problems but the literature (inadvertently) downplays their importance because of the focus on deriving estimators assuming that functional forms are known and by using model comparison techniques to choose between competing specifications. 
  - > While this raises interesting theoretical and computation issues that have been the subject of a growing and thoughtful formal econometric literature, it does not provide a toolbox that gives satisfactory solutions to these problems for applied researchers interested in causality and the economic processes at work. 
  - > It is in this sense that we call into question the approach of the burgeoning body of applied economic research that proceeds with mechanical application of spatial econometric techniques to causal questions of “spillovers” and other forms of spatial interaction, or that estimates spatial lag models as a quick fix for endogeneity issues, or that blindly applies spatial econometric models by default without serious consideration of whether this is necessary given the research question in hand.
  
- [McMillen 2012, _"Perspectives on Spatial Econometrics"_](./literature/mcmillen-2012-regional-science.pdf) 
  - > Standard spatial econometric models have become over-used. 
  - > Though they play a useful role in detecting various forms of model misspecification, they are apt to be viewed as the correct parametric form for a model when, in fact, they are simply a convenient way to control for unknown sources of spatial clustering among model residuals or the
dependent variable. 
  - > Using a spatial weight matrix to form weighted averages of a variable is nothing more than a form of linear smoothing with (typically) an unusually narrow bandwidth. 
  - > Though clever procedures have been proposed for manipulating or simply avoiding working with the large matrices required by standard spatial models, researchers seldom truly believe in the model structure that made them necessary in the first place. 
  - > If the true model structure is unknown and the primary objective is not to estimate a causal effect of Wy on y, there is no compelling reason for choosing spatial AR or error models over other forms of spatial smoothing; indeed, the choice is likely to cause as much harm as good.

- [Corrado and Fingleton 2012, _"Where is the Economics in Spatial Economics?"_](./literature/corrado-and-fingleton-2012-regional-science.pdf) 
  - > We have called for a stronger more theoretical basis for W to supplement the very significant atheoretical empirical foundations that dominate, something that might emerge from current work on games, network formation, dynamics and equilibria that is occurring within the social science, notably within the economics of networks.
  - > We have attempted to show that the concept of the W matrix is however undeniably necessary in one form or another and is in any case almost inescapable. 
  - > It first comes to our attention as a convenient, useful, and succinct representation of spatial interaction, either in the form of endogenous or exogenous lagged variables, and/or as part of an explicit error process.

Finally, there is a related paper by one of the special issues authors called ["Issues in Spatial Data anlysis"](./literature/mcmillen-2010-regional-science.pdf) that discusses shortcomings between how spatial models which may be informative. 

<br>

### Semiparametric spatial models 

The semiparametric approach that McMillen 2012 discusses can be implemented within R as a generalized additive model (GAM) estimated with `mgcv`.

A few different books on GAMs also mention this approach to spatial models - see [here](https://reseau-mexico.fr/sites/reseau-mexico.fr/files/igam.pdf) for Simon Wood's book _Introduction to Generalized Additive Models_, [here](https://m-clark.github.io/generalized-additive-models/appendix.html#time-and-space) for the relevant appendix in Michael Clark's _Generalized Additive Models_.

```{r}
#model the data with semiparametric smooth for lng X lat
semipar_model <- gam(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + 
                       I(RM^2) +AGE + log(DIS) + log(RAD) + TAX + 
                       PTRATIO + B + log(LSTAT) +
                       s(LON, LAT, k = 100),
                     data = boston)

#look at model summary
summary(semipar_model)

#generate predictions
boston$gam_pred <- predict(semipar_model)

#RMSE
sqrt(mean((log(boston$CMEDV) - boston$lm_pred)^2))
sqrt(mean((log(boston$CMEDV) - boston$sdm_pred)^2))
sqrt(mean((log(boston$CMEDV) - boston$gam_pred)^2))

#grab the predictions for mapping
model_compare <- boston %>%
  mutate(sdm_pred = as.numeric(sdm_pred)) %>%
  select(lm_pred, sdm_pred, gam_pred, geometry) %>%
  pivot_longer(-geometry, names_to = "model", values_to = "prediction") %>%
  mutate(prediction = exp(prediction)) %>%
  st_as_sf()

#make map
ggplot(model_compare, aes(fill = prediction)) +
  facet_grid(~ model) +
  geom_sf(color = NA) +
  scale_fill_viridis_c() +
  theme_void()
```
<br>

### Conditional autoregressive (CAR) spatial models

Conditional autoregressive (CAR) models are more common in epidemiology and biostatistics for prediction tasks like disease mapping. According to (Ver Hoef et al 2018 in _Spatial Statistics_)[https://www.stat.colostate.edu/~hooten/papers/pdf/VerHoef_etal_SpatStat_2018.pdf], CAR models can be expressed as SAR models, and vice versa.

A particularly popular flavor of CAR models called _intrinsic_ conditional autoregressive models (ICAR) and conceptualizes spatial structure as a spatial markov process / random walk. Regression models with a spatial ICAR random effect are estimated as Gaussian random fields, a generalization of more familiar Gaussian processes limited to 1 dimension.

The INLA approach to estimating the posterior of these CAR spatial models is popular since it significantly reduces computational time if inference is focused on marginals of the posterior. It is also closer to other R regression modeling interfaces compared to Stan or BUGS, though not without its own eccentricities related to inputs and output structure.

The following example is a no-covariate smoothing model based on the Besags, York and Mollie spatial random effect parameterization, where there is a spatial ICAR random effect for spatial variation and IID random effect for idiosyncratic shocks.

```{r, warning=FALSE}
boston$TOWNNO <- boston$TOWNNO + 1

towns <- boston %>%
  select(TOWNNO) %>%
  summarize(TOWNNO = unique(TOWNNO))

#inla requires a representation of the adjacency matrix be written to storage
nb2INLA("./towns.graph", poly2nb(as_Spatial(towns), row.names = towns$TOWNNO))

#bayesian analysis of ICAR model with inla using only higher-level town identifier
spatial_icar_model <- inla(log(CMEDV) ~ 1 +
                             
                             #this function call specifies the ICAR random effect
                             f(TOWNNO, graph = "./towns.graph", model = "bym"),
                           
                           #we're going to pass a model object sans predictions from
                           #other models and geometry since inla wants a pretty vanilla
                           #data frame object
                           data = boston %>%
                                    select(-ends_with("pred")) %>% 
                                    st_drop_geometry(),
                           
                           #outcome distribution
                           family = "gaussian",
                           
                           #compute fitted value marginals so we can assess predictions
                           control.predictor = list(compute = TRUE),
                           
                           #compute fit criteria if we should want them
                           control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

#the summary output of inla models differs some from frequentist models like lm/glm
summary(spatial_icar_model)

#summary.fitted.values is a data frame with the mean, SD, and quantiles of fitted values
boston$icar_pred <- exp(spatial_icar_model$summary.fitted.values[['0.5quant']])

#reshape for plotting
boston_icar_plot <- boston %>%
  select(CMEDV, icar_pred) %>%
  pivot_longer(-geometry) %>%
  st_as_sf()

#show town smoothing model predictions compared to observed tract level values
ggplot(boston_icar_plot, aes(fill = value)) +
  facet_grid(~ name) +
  geom_sf(color = NA)
```

<br>

