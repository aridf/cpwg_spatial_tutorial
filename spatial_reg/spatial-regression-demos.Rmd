---
title: "Spatial regression demos"
author: "Chris Hess"
date: "5/4/2021"
output:
  github_document:
    df_print: paged
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r}
#dependencies
library(tidyverse)
library(sf)
library(spatialreg)
library(spdep)
library(INLA)

#load the Boston housing Ddata
boston <- read_sf(system.file("shapes/boston_tracts.shp", package = "spData")) %>%
  st_transform(crs = 5070) #epsg for USA Contiguous Albers Equal Area Conic, USGS
```

<br>

## Overview

This vignette is focused on demonstrating code for setting up and estimating spatial regression models in R. The models are focused on the effect of air quality on home values, with the precise specifications drawn from Harris & Rubenfield 1978's original use of the Boston data and a more recent paper (Bivand 2017) that revisits the topic with models estimated in R. 

Check out these papers if interested the nuts and bolts of how the covariate specifications but this should not be material to understanding the setup for these models in R.

<br>

## Boston housing data

For detailed information, check out the `boston` data's R documentation page. This is a set of built-in data that come with the `spData` library that can be loaded like we have above or that can be downloaded from many sources as standalone files (GeoDa's data center, Kaggle, etc.)

```{r, results = "asis"}
?boston
```

Here's a quick look at the data for right now though:

```{r}
glimpse(boston)
```


<br>

### Spatial extent

We map the `boston` data's corrected median home value (`CMEDV`) here for reference.

```{r}
#CMEDV - corrected median values of owner-occupied housing in USD 1000
ggplot(boston, aes(fill = CMEDV)) +
  geom_sf(color = NA) +
  labs(fill = "Median owner-occupied housing value") +
  scale_fill_viridis_b() +
  theme(legend.position = "bottom")
```

<br>

## Getting things ready

<br>

#### Polygon -> Neighborhood list

Contiguity based neighbors are probably the most common type of neighbor lists used for spatial regressions. Here we show how to use function `poly2nb()` to use a spatial object to a create neighborhood list.

`knearneigh` and `knn2nb()` provide an alternative nearest neighbor approach for generating neighborhood lists for reference.

```{r}
#first add a row number that will index neighborhood list entries to relate to df rows
boston <- boston %>% mutate(tract_idx = row_number())

#contiguity neighborhood list can be created with poly2nb (nb: fn wants sp* object not sf)
boston_nb <- poly2nb(as_Spatial(boston), row.names = boston$tract_idx)

#this is a little more useful than the print method for nb objects
summary(boston_nb)
```

<br>

#### Removing empty neighbor sets

NB: regarding zero policy: you technically can set `zero.policy = TRUE` to ignore empty neighbor sets but these models aren't really intended to have isolates / islands. See responses from Roger Bivand (package author) dug up from the R spatial listserv on this matter:

> The lagged value of a no-neighbour observation is not well defined, as setting 0 may be misleading, and setting NA will break the next operations, in this case calculating measures based on the weights.
> If you really want regions with no neighbours, you must use zero.policy = TRUE everwhere - because usually you are advised not to generate such neighbour objects (the theoretical properties of tests etc. were developed for graphs with all regions connected.

You can use subset with the cardinality of the neighborhood list to remove these empty neighbor cases. First remove the corresponding rows from the data frame that will be used for modeling, then remove the neighborhood list entries.

There aren't any islands in these data but the following code is what would be used in the event that there were.

```{r}
boston <- subset(boston, subset = card(boston_nb) > 0)
boston_nb <- subset(boston_nb, subset = card(boston_nb) > 0)
```

<br>

#### Visualizing the neighborhood structure

Sometimes it can be useful to show the neighborhood structure across spatial units as a way of identifying whether this spatial pre-processing is producing the desired outcome.

```{r}
#we need to translate the nb object into a network of vectors for plotting
boston_neighbors_sf <- st_as_sf(nb2lines(boston_nb, coords = coordinates(as_Spatial(boston)),
                                         proj4string = proj4string(as_Spatial(boston))))

#once we have that, we can assemble a map showing the neighborhood structure
ggplot(boston) + 
  geom_sf(fill = 'grey70', color = 'white') +
  geom_sf(data = boston_neighbors_sf, lwd = .1) +
  geom_sf(data = st_centroid(st_geometry(boston)), size = .75) +
  theme_void()
```

<br>

#### Neighborhood list -> spatial weights matrix

The neighborhood list gets us part of the way to where we need to go. The primary spatial regression functions provided by the `spatialreg` library all expect a `listw` spatial weights object that is one step removed from the neighborhood list we've already created. 

`nb2listw()` handles this task of creating a spatial weights object, with row-standardized `style = "W"` (default) or `style = "B"` for binary coding being the most common approaches for constructing spatial weights.

```{r}
#row standardized
boston_listw_w <- nb2listw(boston_nb, style = "W")

#unstandardized
boston_listw_b <- nb2listw(boston_nb, style = "B")
```

<br>

`listw` can be coerced into a sparse matrix that is potentially useful when the data in question are large and estimation of models is producing issues NaNs due to a "poorly conditioned" numerical Hessian. 

We can visualize the matrix with `image()` to see what it describes, though this admittedly isn't super useful. The regression functions eventually take the `sp_powers_traces` created here as as an additional parameter.

```{r}
#coerce to sparse matrix
boston_csparse_matrix <- as(boston_listw_w, "CsparseMatrix")

#visualize the sparse matrix
image(boston_csparse_matrix)

#this is what is used within spatial regression functions in large data cases
boston_listw_powers_traces <- trW(boston_csparse_matrix, type = "mult")
```

<br>

## Estimating spatial models

### Linear regression baseline

```{r}
#estimate the Harrison and Rubenfield model for housing price ~ air quality 
linear_model <- lm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT), 
                   data = boston)

#look at model coefficients
summary(linear_model)

#add column of fitted values to boston sf object
boston$lm_pred <- predict(linear_model)
```

<br>

### Residual spatial autocorrelation

#### Map the residual spatial autocorrelation

```{r}
#choropleth map to investigate spatial structure in residuals
ggplot(boston, aes(fill = log(CMEDV) - lm_pred)) +
  geom_sf(color = NA) +
  scale_fill_gradient2()
```

```{r}
#aspatial plots for residual analysis
#plot(linear_model)
```
<br>

#### Moran's I test for residual spatial autocorrelation

```{r}
#test for residual spatial autocorrelation with Moran's I
lm.morantest(linear_model, boston_listw_w)
```

<br>

#### Lagrage multiplier diagnostics for spatial dependence

```{r}
lm.LMtests(linear_model, boston_listw_w, test = "all")
```

<br>

### Spatial models

Simultaneous autoregressive models are typically estimated with maximum likelihood and most commonly found in papers from economics, sociology and other social sciences where inference on a particular association is the primary objective.

There are also full Bayesian methods for SAR models in various frameworks like stan and INLA.

<br>

#### Three spatial extensions from OLS

1. Endogenous interaction
2. Exogenous interaction effects
3. Spatially structured error terms

Any combination of these can be incorporated under what is called the General Nesting Spatial Model, but it is useful to go through each individually first.

<br>

#### Spatial lag model (SLM)

Spatial lag models are used to capture when a dependent variable y in place i is affected by the independent variables in both place i and j. 

This spatial dependence between units violates the OLS assumption of independent error terms as well as the assumption of independence of observations, so resulting estimates are potentially biased and inefficient. 

These models estimate a term $\rho$ that denotes the spatial dependence, whether this is positive (reflects diffusion across like places) or negative (reflects resistance process like places)

```{r, message = FALSE, warning = FALSE}
#estimate spatial lag model
spatial_lag_model <- lagsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                              data = boston,
                              listw = boston_listw_w)

#summary of spatial lag model
summary(spatial_lag_model)

#fitted values from spatial lag model
boston$slm_pred <- predict(spatial_lag_model)

#to pass the vector of powered spatial weights matrix traces output by trW
#according to the docs "when given, insert the asymptotic analytical values 
#into the numerical Hessian instead of the approximated values; may be used to 
#get around some problems raised when the numerical Hessian is poorly conditioned, 
#generating NaNs in subsequent operations;
# lagsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#            AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#          data = boston,
#          listw = boston_listw_w,
#          method = "Matrix",
#          trs = boston_listw_powers_traces)
```

<br>

#### Spatial error model (SEM)

Spatial error refers to when the error terms across different spatial units are correlated and can reflect omitted, spatially-correlated covariates that would bias inference on a focal term. Spatial error in linear regression only violates the assumption of uncorrelated error terms, making estimates inefficient. 

The spatial error model (SEM) is thus more of a nuisance correction than a substantively different model from linear regression like spatial lag models. That is, the error term is decomposed into a spatially structured component based on neighbors, and a non-structured component that captures the rest.

```{r, message = FALSE, warning = FALSE}
#estimate spatial error model
spatial_error_model <- errorsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                                  data = boston,
                                  listw = boston_listw_w)

#summary of spatial error model
summary(spatial_error_model)

#fitted values from spatial error model
boston$sem_pred <- predict(spatial_error_model)
```

<br>

#### Spatial Durbin model (SDM)

Direct effects via regular terms, indirect effects via spatially lagged terms. 

```{r, message = FALSE, warning = FALSE}
spatial_durbin_model <- lagsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                                 data = boston,
                                 listw = boston_listw_w,
                                 Durbin = TRUE) 
#sumamry of spatial durbin model
summary(spatial_durbin_model)

#fitted values for spatial durbin model
boston$sdm_pred <- predict(spatial_durbin_model)

#estimate spatial error durbin
# errorsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#             AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#            data = boston,
#            listw = boston_listw_w,
#            Durbin = TRUE) 

#you can also do a "spatial lag of x" model with only a set of spatially lagged covariates
# errorsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#             AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#            data = boston,
#            listw = boston_listw_w,
#            Durbin = ~ CRIM) 
```

<br>

#### General nested spatial model (GNSM)

This model includes a spatially lagged dependent variable, spatially lagged independent variables and spatially structured error terms. It is essentially a combined version of all three spatial extensions to OLS. 

Without the spatially lagged independent variables (i.e. the Durbin component) it is known as a simulataneous autoregressive combined (SAC) / simulataneous autoregressive-autoregressive (SARAR) model.

```{r, message = FALSE, warning = FALSE}
#estimate general nested spatial model
spatial_nested_model <- sacsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
                                    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
                                 data = boston,
                                 listw = boston_listw_w,
                                 Durbin = TRUE) 

#summary for general nested spatial model 
summary(spatial_nested_model)

#estimate spatial autoregressive combined (SAC/SARAR) model
# spatial_combined_model <- sacsarlm(log(CMEDV) ~ I(NOX^2) + CRIM + ZN + INDUS + CHAS + I(RM^2) +
#                                     AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
#                                    data = boston,
#                                    listw = boston_listw_w,
#                                    durbin = TRUE) 
```

<br>

#### Impacts

A quantity known as the model impacts are needed to properly understand model associations when there are spatially lagged predictors or outcomes. These parse out the effect into direct and indirect effects of a covariate on the outcome. See below for how the `spatialreg` documentation describes this:

> The calculation of impacts for spatial lag and spatial Durbin models is needed in order to interpret the regression coefficients correctly, because of the spillovers between the terms in these data generation processes (unlike the spatial error model). 

The `impacts()` function will greatly simplify the estimation of overall impacts for a given term, but does produce an odd data.frame-like structure that isn't readily coercable / usable as an actual data frame.

Accordingly, we use `imap()` and `reduce()` to iterate through our models, computing the impacts and then wrangling results into what is ultimately a list of data frames rather than a list of `lagImpact` objects by default.

```{r, message=FALSE, warning=FALSE}
#compute impacts
impacts <- imap(list(spatial_lag_model, spatial_durbin_model, spatial_nested_model),
               
                #for each list element, compute impacts
                ~ impacts(.x, listw = boston_listw_w) %>%
                  
                  #reduce to a data frame per model
                  reduce(bind_cols) %>%
                  
                  #fix the column names that are lost
                  rename(direct = ...1, indirect = ...2, total = ...3) %>%
                  
                  #label the model the impacts correspond to based on list elt
                  mutate(model = .y))

#reduce list to data frame
impacts <- reduce(impacts, bind_rows)
```

```{r}
#make the model measure informative
impacts <- impacts %>% 
  mutate(model = case_when(
    model == 1 ~ "1. Spatial Lag Model",
    model == 2 ~ "2. Spatial Durbin Model",
    model == 3 ~ "3. Nested Spatial Model"
  ))

#we need to readd the covariate names, sans intercept and Rho
impacts$term <- rep(names(coefficients(spatial_lag_model)[-c(1:2)]), 3)

#pivot longer for ggplot
impacts <- impacts %>%
  pivot_longer(-c(model, term, total)) 


ggplot(impacts, aes(y = term, x = value, fill = name)) +
  facet_grid(~ model) +
  geom_bar(stat = "identity", position = "stack")
```

We can then visualize

<br>

#### Conditional autoregressive (CAR) spatial models

Conditional autoregressive (CAR) models are more common in epidemiology and biostatistics for prediction tasks like disease mapping. According to (Ver Hoef et al 2018 in _Spatial Statistics_)[https://www.stat.colostate.edu/~hooten/papers/pdf/VerHoef_etal_SpatStat_2018.pdf], CAR models can be expressed as SAR models, and vice versa.

A particularly popular flavor of CAR models called _intrinsic_ conditional autoregressive models (ICAR) and conceptualizes spatial structure as a spatial markov process / random walk. Regression models with a spatial ICAR random effect are estimated as Gaussian random fields, a generalization of more familiar Gaussian processes limited to 1 dimension.

The INLA approach to estimating the posterior of these CAR spatial models is popular since it significantly reduces computational time if inference is focused on marginals of the posterior. It is also closer to other R regression modeling interfaces compared to Stan or BUGS, though not without its own eccentricities related to inputs and output structure.

The following example is a no-covariate smoothing model based on the Besags, York and Mollie spatial random effect parameterization, where there is a spatial ICAR random effect for spatial variation and IID random effect for idiosyncratic shocks.

```{r, warning=FALSE}
boston$TOWNNO <- boston$TOWNNO + 1

towns <- boston %>%
  select(TOWNNO) %>%
  summarize(TOWNNO = unique(TOWNNO))

#inla requires a representation of the adjacency matrix be written to storage
nb2INLA("./towns.graph", poly2nb(as_Spatial(towns), row.names = towns$TOWNNO))

#bayesian analysis of ICAR model with inla using only higher-level town identifier
spatial_icar_model <- inla(log(CMEDV) ~ 1 +
                             
                             #this function call specifies the ICAR random effect
                             f(TOWNNO, graph = "./towns.graph", model = "bym"),
                           
                           #we're going to pass a model object sans predictions from
                           #other models and geometry since inla wants a pretty vanilla
                           #data frame object
                           data = boston %>%
                                    select(-ends_with("pred")) %>% 
                                    st_drop_geometry(),
                           
                           #outcome distribution
                           family = "gaussian",
                           
                           #compute fitted value marginals so we can assess predictions
                           control.predictor = list(compute = TRUE),
                           
                           #compute fit criteria if we should want them
                           control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

#the summary output of inla models differs some from frequentist models like lm/glm
summary(spatial_icar_model)

#summary.fitted.values is a data frame with the mean, SD, and quantiles of fitted values
boston$icar_pred <- exp(spatial_icar_model$summary.fitted.values[['0.5quant']])

#reshape for plotting
boston_icar_plot <- boston %>%
  select(CMEDV, icar_pred) %>%
  pivot_longer(-geometry) %>%
  st_as_sf()

#show town smoothing model predictions compared to observed tract level values
ggplot(boston_icar_plot, aes(fill = value)) +
  facet_grid(~ name) +
  geom_sf(color = NA)
```








